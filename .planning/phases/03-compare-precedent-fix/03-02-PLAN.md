---
phase: 03-compare-precedent-fix
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - app/api/routes.py
  - app/services/matching_service.py
  - app/static/js/precedent.js
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Clause matching uses TF-IDF vectorization for better concept-based matching"
    - "When precedent panel opens, view auto-jumps to first matched clause"
    - "Matching quality is improved over simple keyword overlap"
  artifacts:
    - path: "app/services/matching_service.py"
      provides: "TF-IDF-based clause matching"
      contains: "TfidfVectorizer"
    - path: "app/api/routes.py"
      provides: "Updated endpoint using new matching service"
      contains: "matching_service"
    - path: "app/static/js/precedent.js"
      provides: "Auto-jump to first match on open"
      contains: "scrollToFirstRelated"
  key_links:
    - from: "app/api/routes.py"
      to: "app/services/matching_service.py"
      via: "import and function call"
      pattern: "from app.services.matching_service import"
    - from: "app/static/js/precedent.js"
      to: "/api/precedent"
      via: "fetch call with auto-scroll"
      pattern: "scrollToFirstRelated"
---

<objective>
Improve clause matching quality using TF-IDF vectorization and auto-jump to first match.

Purpose: Fix UAT issue #5 (clause matching quality is "iffy") and UAT issue #3 (should auto-jump to first match). Current keyword overlap approach misses conceptually similar clauses with different wording.

Output: New matching service using scikit-learn TF-IDF, updated API endpoint, auto-scroll behavior on panel open.
</objective>

<execution_context>
@C:\Users\david\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\david\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/03-compare-precedent-fix/03-RESEARCH.md

# Existing files to modify
@C:\Users\david\Documents\claude-redlining\app\api\routes.py
@C:\Users\david\Documents\claude-redlining\app\static\js\precedent.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TF-IDF matching service</name>
  <files>app/services/matching_service.py</files>
  <action>
Create new file `app/services/matching_service.py` with TF-IDF-based clause matching:

```python
"""
Clause Matching Service using TF-IDF vectorization.

Provides better concept-based matching than simple keyword overlap.
Uses scikit-learn TfidfVectorizer for fast, accurate similarity scoring.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from typing import List, Dict, Any, Optional


class ClauseMatcher:
    """
    Match clauses between target and precedent documents using TF-IDF similarity.
    """

    def __init__(self, threshold: float = 0.25):
        """
        Initialize matcher with similarity threshold.

        Args:
            threshold: Minimum similarity score to consider a match (0-1).
                       Lower = more matches but possibly less relevant.
                       Default 0.25 works well for legal text.
        """
        self.threshold = threshold
        self.vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),  # Unigrams and bigrams
            stop_words='english',
            min_df=1,
            max_df=0.95,  # Ignore terms in >95% of docs (too common)
            lowercase=True,
            strip_accents='unicode'
        )

    def find_matches(
        self,
        target_clauses: List[Dict[str, Any]],
        precedent_clauses: List[Dict[str, Any]],
        target_para_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Find matching clauses between target and precedent documents.

        Args:
            target_clauses: List of clause dicts with 'id', 'text', 'section_ref'
            precedent_clauses: List of clause dicts from precedent doc
            target_para_id: If provided, only match for this specific paragraph

        Returns:
            List of match dicts with source info, target info, and confidence score
        """
        if not target_clauses or not precedent_clauses:
            return []

        # Extract text for vectorization
        target_texts = [c.get('text', '') for c in target_clauses]
        precedent_texts = [c.get('text', '') for c in precedent_clauses]

        # Filter to specific target if requested
        if target_para_id:
            target_idx = next(
                (i for i, c in enumerate(target_clauses) if c.get('id') == target_para_id),
                None
            )
            if target_idx is None:
                return []
            target_texts = [target_texts[target_idx]]
            target_clauses = [target_clauses[target_idx]]

        # Skip empty texts
        valid_target_indices = [i for i, t in enumerate(target_texts) if t.strip()]
        valid_prec_indices = [i for i, t in enumerate(precedent_texts) if t.strip()]

        if not valid_target_indices or not valid_prec_indices:
            return []

        # Build combined corpus for consistent vocabulary
        all_texts = [target_texts[i] for i in valid_target_indices] + \
                    [precedent_texts[i] for i in valid_prec_indices]

        try:
            # Fit and transform
            tfidf_matrix = self.vectorizer.fit_transform(all_texts)

            n_targets = len(valid_target_indices)
            target_vectors = tfidf_matrix[:n_targets]
            precedent_vectors = tfidf_matrix[n_targets:]

            # Compute similarity matrix
            similarity_matrix = cosine_similarity(target_vectors, precedent_vectors)

        except ValueError:
            # Empty vocabulary after preprocessing
            return []

        # Extract matches above threshold
        matches = []

        for i, target_idx in enumerate(valid_target_indices):
            target_clause = target_clauses[target_idx]

            # Get all precedent scores for this target
            scores = similarity_matrix[i]

            # Find best matches above threshold
            for j, prec_idx in enumerate(valid_prec_indices):
                score = scores[j]

                if score >= self.threshold:
                    prec_clause = precedent_clauses[prec_idx]

                    matches.append({
                        'id': prec_clause.get('id'),
                        'text': prec_clause.get('text', ''),
                        'section_ref': prec_clause.get('section_ref', ''),
                        'caption': prec_clause.get('caption'),
                        'hierarchy': prec_clause.get('section_hierarchy', []),
                        'score': round(float(score), 3),
                        'source_para_id': target_clause.get('id'),
                        'source_section_ref': target_clause.get('section_ref', '')
                    })

        # Sort by score descending
        matches.sort(key=lambda x: x['score'], reverse=True)

        # Deduplicate - keep highest score for each precedent clause
        seen_ids = set()
        unique_matches = []
        for m in matches:
            if m['id'] not in seen_ids:
                seen_ids.add(m['id'])
                unique_matches.append(m)

        return unique_matches[:15]  # Limit to top 15 matches


def find_related_clauses(
    target_para: Dict[str, Any],
    precedent_content: List[Dict[str, Any]],
    threshold: float = 0.25
) -> List[Dict[str, Any]]:
    """
    Convenience function to find precedent clauses related to a target paragraph.

    Args:
        target_para: Target paragraph dict
        precedent_content: Full precedent document content list
        threshold: Similarity threshold

    Returns:
        List of related precedent clauses with scores
    """
    # Filter to paragraphs only
    target_clauses = [target_para]
    precedent_clauses = [
        item for item in precedent_content
        if item.get('type') == 'paragraph' and item.get('text', '').strip()
    ]

    matcher = ClauseMatcher(threshold=threshold)
    return matcher.find_matches(target_clauses, precedent_clauses)


# Also provide section-level matching for navigator highlighting
def match_sections(
    target_sections: List[Dict[str, Any]],
    precedent_sections: List[Dict[str, Any]],
    threshold: float = 0.3
) -> Dict[str, List[str]]:
    """
    Match sections by title/caption similarity.

    Returns dict mapping target section IDs to list of matching precedent section IDs.
    """
    if not target_sections or not precedent_sections:
        return {}

    target_titles = [s.get('title', '') or s.get('caption', '') for s in target_sections]
    prec_titles = [s.get('title', '') or s.get('caption', '') for s in precedent_sections]

    # Filter empty
    valid_targets = [(i, t) for i, t in enumerate(target_titles) if t.strip()]
    valid_precs = [(i, t) for i, t in enumerate(prec_titles) if t.strip()]

    if not valid_targets or not valid_precs:
        return {}

    vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')

    try:
        all_titles = [t for _, t in valid_targets] + [t for _, t in valid_precs]
        tfidf = vectorizer.fit_transform(all_titles)

        n_targets = len(valid_targets)
        sim_matrix = cosine_similarity(tfidf[:n_targets], tfidf[n_targets:])
    except ValueError:
        return {}

    matches = {}
    for i, (target_idx, _) in enumerate(valid_targets):
        target_id = target_sections[target_idx].get('para_id', '')
        matched_prec_ids = []

        for j, (prec_idx, _) in enumerate(valid_precs):
            if sim_matrix[i, j] >= threshold:
                prec_id = precedent_sections[prec_idx].get('para_id', '')
                matched_prec_ids.append(prec_id)

        if matched_prec_ids:
            matches[target_id] = matched_prec_ids

    return matches
```

Ensure scikit-learn is available (check requirements.txt or install):
```bash
pip install scikit-learn
```
  </action>
  <verify>
- File exists at app/services/matching_service.py
- `python -c "from app.services.matching_service import ClauseMatcher; print('OK')"` works
- No import errors for sklearn
  </verify>
  <done>TF-IDF matching service is created and importable</done>
</task>

<task type="auto">
  <name>Task 2: Update API endpoint to use TF-IDF matching</name>
  <files>app/api/routes.py</files>
  <action>
1. Add import at top of routes.py:
   ```python
   from app.services.matching_service import find_related_clauses
   ```

2. Replace the existing `get_related_precedent_clauses()` function's matching logic. Find the function that starts with `@api_bp.route('/precedent/<session_id>/related/<para_id>'`.

3. Replace the keyword-overlap-based scoring with a call to the new matching service:

   ```python
   @api_bp.route('/precedent/<session_id>/related/<para_id>', methods=['GET'])
   def get_related_precedent_clauses(session_id, para_id):
       """
       Find clauses in the precedent document that relate to a specific paragraph
       in the target document.

       Uses TF-IDF vectorization for concept-based matching.

       PREC-03: System highlights clauses in precedent that relate to current paragraph
       """
       from app.services.matching_service import find_related_clauses

       session = get_session(session_id)
       if not session:
           return jsonify({'error': 'Session not found'}), 404

       parsed_precedent = session.get('parsed_precedent')
       if not parsed_precedent:
           return jsonify({'error': 'No precedent document available', 'has_precedent': False}), 404

       # Find the target paragraph
       parsed_doc = session.get('parsed_doc')
       if not parsed_doc:
           return jsonify({'error': 'Document not found'}), 404

       target_para = None
       for item in parsed_doc.get('content', []):
           if item.get('type') == 'paragraph' and item.get('id') == para_id:
               target_para = item
               break

       if not target_para:
           return jsonify({'error': 'Paragraph not found'}), 404

       # Use TF-IDF matching service
       precedent_content = parsed_precedent.get('content', [])
       related_clauses = find_related_clauses(
           target_para=target_para,
           precedent_content=precedent_content,
           threshold=0.25  # Configurable threshold
       )

       return jsonify({
           'session_id': session_id,
           'para_id': para_id,
           'target_section_ref': target_para.get('section_ref', ''),
           'related_clauses': related_clauses,
           'total_matches': len(related_clauses)
       })
   ```

4. The old regex-based matching code can be removed (the entire block with stop_words, keyword extraction, and manual scoring).
  </action>
  <verify>
- Flask app starts without import errors
- API endpoint /precedent/{session_id}/related/{para_id} returns matches with 'score' field
- Scores are now 0-1 floats from TF-IDF similarity
  </verify>
  <done>API endpoint uses TF-IDF matching service for better clause matching</done>
</task>

<task type="auto">
  <name>Task 3: Auto-jump to first match when panel opens</name>
  <files>app/static/js/precedent.js</files>
  <action>
1. Modify `comparePrecedent()` function to auto-scroll after panel opens. After calling `openPrecedentPanel()`, add a delayed call to scroll to first match:

   ```javascript
   async function comparePrecedent() {
       // ... existing validation code ...

       try {
           // Fetch precedent document
           const precedentData = await api(`/precedent/${AppState.sessionId}`);

           if (!precedentData.has_precedent) {
               showToast('No precedent document available for this session', 'warning');
               return;
           }

           // Store precedent data
           precedentPanelState.document = precedentData;
           precedentPanelState.filename = precedentData.filename;
           precedentPanelState.sections = precedentData.sections || [];
           precedentPanelState.currentParaId = AppState.selectedParaId;

           // Fetch related clauses for current paragraph
           await fetchRelatedPrecedentClauses(AppState.selectedParaId);

           // Render and show the panel
           renderPrecedentPanel();
           openPrecedentPanel();

           // AUTO-JUMP: Scroll to first match after panel renders (UAT #3)
           // Use setTimeout to ensure DOM is ready
           setTimeout(() => {
               autoJumpToFirstMatch();
           }, 300);

       } catch (error) {
           // ... existing error handling ...
       }
   }
   ```

2. Create the `autoJumpToFirstMatch()` function:

   ```javascript
   /**
    * Auto-jump to first matched clause when panel opens (UAT #3)
    */
   function autoJumpToFirstMatch() {
       if (precedentPanelState.relatedClauseIds.length === 0) {
           // No matches - just show the panel without scrolling
           return;
       }

       const firstMatchId = precedentPanelState.relatedClauseIds[0];

       // Scroll precedent content to first match
       const precedentContentEl = document.getElementById('precedent-content-body');
       const matchEl = document.getElementById(`prec-${firstMatchId}`);

       if (precedentContentEl && matchEl) {
           // Scroll match into view
           matchEl.scrollIntoView({ behavior: 'smooth', block: 'center' });

           // Add highlight flash
           matchEl.classList.add('precedent-highlight-flash');
           setTimeout(() => {
               matchEl.classList.remove('precedent-highlight-flash');
           }, 1500);
       }

       // Update navigator to show first match as active
       const navItem = document.querySelector(`.precedent-nav-item[data-para-id="${firstMatchId}"]`);
       if (navItem) {
           document.querySelectorAll('.precedent-nav-item.active').forEach(el => {
               el.classList.remove('active');
           });
           navItem.classList.add('active');
       }

       // Show toast with match count
       const matchCount = precedentPanelState.relatedClauseIds.length;
       showToast(`Found ${matchCount} related clause${matchCount !== 1 ? 's' : ''} in precedent`, 'info');
   }
   ```

3. Update `scrollToFirstRelated()` to also work well as a manual action (the button still exists in footer):

   ```javascript
   function scrollToFirstRelated() {
       if (precedentPanelState.relatedClauseIds.length > 0) {
           autoJumpToFirstMatch();
       } else {
           showToast('No related clauses found for current selection', 'info');
       }
   }
   ```

4. Export the new function:
   ```javascript
   window.autoJumpToFirstMatch = autoJumpToFirstMatch;
   ```
  </action>
  <verify>
- Open precedent panel
- VERIFY: View automatically scrolls to first matched clause
- VERIFY: Match is highlighted with flash animation
- VERIFY: Toast shows "Found N related clauses"
- VERIFY: "Jump to First Match" button still works manually
  </verify>
  <done>Panel auto-jumps to first match when opening (UAT #3 fixed)</done>
</task>

</tasks>

<verification>
1. Load app with session containing precedent document
2. Select a clause in main document
3. Click "Compare Precedent"
4. VERIFY: Panel opens and immediately scrolls to first matched clause
5. VERIFY: Match quality is improved (conceptually similar clauses match, not just keyword overlap)
6. Select different clauses and verify matches update
7. Check console for any errors
</verification>

<success_criteria>
- TF-IDF matching service works and improves match quality (UAT #5 addressed)
- Auto-jump scrolls to first match on panel open (UAT #3 fixed)
- Match scores are 0-1 floats based on cosine similarity
- No regression in panel functionality
- scikit-learn dependency is handled (documented or in requirements.txt)
</success_criteria>

<output>
After completion, create `.planning/phases/03-compare-precedent-fix/03-02-SUMMARY.md`
</output>
